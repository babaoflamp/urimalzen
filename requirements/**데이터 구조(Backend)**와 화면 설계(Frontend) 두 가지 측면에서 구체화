# **데이터 구조(Backend)**와 화면 설계(Frontend) 두 가지 측면에서 구체화

제시해주신 **Technical Note(로직 요약)**는 실제 앱 개발에 바로 적용할 수 있을 만큼 구체적입니다. 이 로직이 개발 단계에서 어떻게 구현되어야 하는지, **데이터 구조(Backend)**와 **화면 설계(Frontend)** 두 가지 측면에서 구체화해 드리겠습니다.

개발팀과 디자이너에게 바로 전달할 수 있는 형태입니다.

---

### 1. 🗄️ 데이터베이스 스키마 예시 (JSON 구조)

이 구조는 **Context Tagging**과 **Level-Aware** 로직을 지원하도록 설계되었습니다. NoSQL(MongoDB 등) 문서를 가정했습니다.

JSON

# 

`{
  "_id": "voc_001_pharmacy",
  "term": "처방전",
  "meaning": "Prescription",
  "category": "Vocabulary",
  
  // 1. Level-Aware Logic: 사용자 레벨(KIIP 단계)에 따른 필터링 용도
  "difficulty_level": {
    "kiip_stage": 2,  // KIIP 2단계
    "cefr": "A2"
  },

  // 2. Context Tagging: 상황별 우선 노출을 위한 태그
  "context_tags": [
    "Hospital",
    "Pharmacy",
    "Health"
  ],

  // 3. Phoneme Analysis Logic: 발음 교정 엔진이 참고할 기준 데이터
  "pronunciation_data": {
    "standard_text": "처방전",
    "pronunciation_text": "처방전", // 음운 변동이 있는 경우 표기 (예: 독립 -> 동닙)
    "phoneme_sequence": ["ch", "eo", "b", "a", "ng", "j", "eo", "n"], // 표준 음소 시퀀스
    "audio_url": "https://api.app/assets/audio/voc_001.mp3"
  },

  // 4. Generated Examples: AI가 미리 생성해 둔(혹은 캐싱된) 레벨 맞춤형 예문
  "examples": [
    {
      "sentence": "약국에서 처방전을 냈어요.",
      "translation": "I submitted the prescription at the pharmacy.",
      "grammar_focus": ["-에서 (place particle)", "-을/를 (object particle)"],
      "generated_for_level": 2 // 레벨 2 타겟 예문
    }
  ]
}`

> 💡 개발자 노트:
> 
> - `phoneme_sequence`: STT 엔진이 사용자의 음성을 분석한 후, 이 배열과 일치율(Similarity)을 계산하여 점수를 매깁니다.
> - `context_tags`: 사용자가 "병원 갈 때 쓸 표현"을 선택하면, 이 배열에 'Hospital'이 포함된 도큐먼트를 쿼리(`find({ context_tags: "Hospital" })`)합니다.

---

### 2. 📱 발음 교정 화면 UI 와이어프레임 (상세)

학습자가 문장을 읽고 피드백을 받는 화면입니다. **음소 단위 분석(Phoneme Analysis)** 결과가 시각적으로 어떻게 표현되는지에 집중했습니다.

### **화면 구성요소 (위에서 아래로)**

1. **상단: 타겟 문장 카드 (Level-Aware)**
    - **문장:** "약국에 **처방전**을 주세요." (학습 단어 강조)
    - **태그:** `#Pharmacy` `#KIIP_Level_2` (Context Tagging 노출)
    - **듣기 버튼:** 🔊 (원어민 음성 재생)
2. **중단: 녹음 인터페이스**
    - **마이크 버튼:** 🎙️ (터치하여 녹음 시작)
    - **실시간 파형:** 사용자의 목소리 톤과 크기를 시각화 (Visual Feedback)
3. **하단: 분석 결과 (STT & Phoneme Analysis)**
    - **종합 점수:** **"85점 - 훌륭해요!"** (Circle Progress Bar)
    - **상세 교정 (핵심 기능):** 사용자가 틀린 발음을 붉은색으로 표시하고, 올바른 발음법을 안내합니다.
    
    > [화면 예시 - 발음 상세 피드백]
    > 
    
    > 내 발음: 처 빵 전 (❌)
    > 
    > 
    > 표준 발음: 처 방 전 (⭕)
    > 
    
    > AI 코칭: "‘ㅂ’ 발음이 너무 셉니다(된소리). 입술에 힘을 조금 빼고 부드럽게 ‘방’이라고 해보세요."음소 차이: [pp, a, ng] detected vs [b, a, ng] expected.
    > 
4. **최하단: 다음 행동 (Action)**
    - [다시 시도하기] / [다음 문장으로 (병원 상황)]

---

### 🎯 이 단계의 핵심 포인트 요약

1. **데이터와 UI의 연결:** JSON의 `phoneme_sequence` 데이터가 UI의 **'상세 교정'** 영역에서 사용자와 표준 발음을 비교하는 기준값이 됩니다.
2. **레벨 제어:** UI 상단의 문장은 JSON의 `generated_for_level: 2` 데이터만 불러와서, 초급자에게 너무 어려운 문장이 노출되지 않도록 막습니다.

---

**다음으로 제가 무엇을 도와드릴까요?**

다음 중 가장 도움이 될 만한 작업을 선택해 주세요:

1. **음소 비교 알고리즘 로직 상세화:** 사용자의 음소(예: `p`)와 정답(`b`)을 비교하여 "입술에 힘을 빼세요" 같은 피드백 텍스트를 생성하는 **Rule-based 로직(의사코드)** 작성.
2. **프롬프트 엔지니어링:** "KIIP 2단계 수준으로 병원 관련 예문을 만들어줘"라고 AI에게 요청할 **실제 시스템 프롬프트(System Prompt)** 초안 작성.
3. **화면 플로우 차트:** 메인 화면에서 주제 선택 후 발음 교정까지 이어지는 **User Flow Diagram** 작성.
